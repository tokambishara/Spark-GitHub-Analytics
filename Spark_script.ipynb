{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ca2279-468b-4d91-b2aa-7d40f00b2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa47b59a-75ca-4ea3-92d4-ec5677154a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestSpark\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3ad53df-29c2-4282-86d4-a3cfbc5ab67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"./*.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2669d8e-a7eb-451d-87e1-07b012082a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.groupBy(\"language\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "725edfb8-d86e-4879-ad72-ecc91ff6f477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                        (0 + 11) / 11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|  language|count|\n",
      "+----------+-----+\n",
      "|        C#|  336|\n",
      "|     Terra|    1|\n",
      "|  Makefile|   36|\n",
      "|       VBA|    3|\n",
      "|      Cuda|   12|\n",
      "|       Arc|    1|\n",
      "|      Rust|  165|\n",
      "|JavaScript| 5293|\n",
      "|      TSQL|    9|\n",
      "|      Perl|   14|\n",
      "|    Puppet|    4|\n",
      "|    Erlang|    6|\n",
      "|      null| 1425|\n",
      "|     Jinja|   14|\n",
      "|       C++|  952|\n",
      "|        F#|    2|\n",
      "|    Groovy|   16|\n",
      "|       TeX|   43|\n",
      "|     OCaml|   16|\n",
      "|      MQL5|    1|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08f6303e-3342-4a91-a2c6-5ef699890225",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg2_url = \"jdbc:postgresql://hadoop-hive-spark-docker-master-metastore-1:5432/sparkdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "211ad8fd-60ef-429a-b78b-2fc55a5e9d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "result.write.format(\"jdbc\").option(\"url\", pg2_url).option(\"dbtable\", \"programming_lang\").option(\"user\", \"postgres\").option(\"password\", \"1234\").option(\"driver\", \"org.postgresql.Driver\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2da0d82e-d00b-4e04-b066-bb5354eb1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39248c11-2a04-493e-a355-1a1414b2313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = df.filter(df['type'] == 'Organization').groupBy('username').agg(sum(col('stars').cast('int')).alias('total_stars'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8da52125-9d27-4395-90ac-ba53939c0260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+\n",
      "|          username|total_stars|\n",
      "+------------------+-----------+\n",
      "|              didi|       4914|\n",
      "|          twosigma|       6150|\n",
      "|       intel-spark|         91|\n",
      "|     Azure-Samples|       1398|\n",
      "|            seznam|         81|\n",
      "|          Qihoo360|      18582|\n",
      "|          snowlift|         26|\n",
      "|    adobe-research|        367|\n",
      "|music-of-the-ainur|         22|\n",
      "|           Alluxio|      16520|\n",
      "|            cdapio|         81|\n",
      "|    USCDataScience|        390|\n",
      "|            cerner|        128|\n",
      "|    HadoopGenomics|         70|\n",
      "|     dk-stationery|         11|\n",
      "|          uosdmlab|         53|\n",
      "|             arkig|          5|\n",
      "|         OpenMined|      16100|\n",
      "|      Salmon-Brain|         10|\n",
      "|       oap-project|          7|\n",
      "+------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbcb06be-f117-437f-8075-fc9a95dede0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.write.format(\"jdbc\").option(\"url\", pg2_url).option(\"dbtable\", \"organizations_stars\").option(\"user\", \"postgres\").option(\"password\", \"1234\").option(\"driver\", \"org.postgresql.Driver\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cde1a464-ab58-4726-9adb-fbb930b6459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import input_file_name, regexp_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ac5847b-b13a-46b7-8395-8432d72012a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=spark.read.json(\"./*.json\").withColumn(\"search_term\",input_file_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46d90f97-3971-4a90-b95e-3e9631692ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.withColumn(\"search_term\", regexp_extract(df2[\"search_term\"], r\"([^/]+)\\.json$\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48997dfc-e5e5-431f-a524-650aab65b09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+--------------------+-----+--------------------+---------+----------------+-----------+--------------------+-----+-----------+--------------------+------------+-------------------+-----------+\n",
      "|_corrupt_record|            created|         description|forks|           full_name|       id|        language|open_issues|           repo_name|stars|subscribers|              topics|        type|           username|search_term|\n",
      "+---------------+-------------------+--------------------+-----+--------------------+---------+----------------+-----------+--------------------+-----+-----------+--------------------+------------+-------------------+-----------+\n",
      "|           null|2014-02-25 08:00:08|Apache Spark - A ...|25357|        apache/spark| 17165658|           Scala|        242|               spark|32296|       2080|[python, scala, r...|Organization|             apache|      Spark|\n",
      "|           null|2017-08-09 19:39:59|Distributed train...| 2027|     horovod/horovod| 99846383|          Python|        298|             horovod|12219|        334|[tensorflow, uber...|Organization|            horovod|      Spark|\n",
      "|           null|2014-08-08 07:30:51|Notes talking abo...| 1773|JerryLead/SparkIn...| 22749672|            null|         27|      SparkInternals| 4774|        619|                  []|        User|          JerryLead|      Spark|\n",
      "|           null|2019-04-22 18:56:51|An open-source st...|  985|      delta-io/delta|182849188|           Scala|        180|               delta| 4164|        188|[spark, acid, big...|Organization|           delta-io|      Spark|\n",
      "|           null|2017-01-20 18:15:57|TensorFlowOnSpark...|  966|yahoo/TensorFlowO...| 79584587|          Python|          6|   TensorFlowOnSpark| 3768|        286|[tensorflow, spar...|Organization|              yahoo|      Spark|\n",
      "|           null|2019-01-03 21:46:54|Koalas: pandas AP...|  333|   databricks/koalas|164026325|          Python|        103|              koalas| 3095|        222|[spark, pandas, p...|Organization|         databricks|      Spark|\n",
      "|           null|2014-08-21 23:07:47|REST job server f...| 1003|spark-jobserver/s...| 23205911|           Scala|        106|     spark-jobserver| 2767|        219|[spark, rest-api,...|Organization|    spark-jobserver|      Spark|\n",
      "|           null|2017-05-05 02:27:30|Distributed Tenso...|  714|intel-analytics/a...| 90328920|Jupyter Notebook|        560|       analytics-zoo| 2483|        102|[apache-spark, de...|Organization|    intel-analytics|      Spark|\n",
      "|           null|2019-07-04 17:09:41|Distributed compu...|  148|ballista-compute/...|195277793|            Rust|          0|            ballista| 2285|         71|[rust, arrow, dat...|Organization|   ballista-compute|      Spark|\n",
      "|           null|2018-08-07 20:55:14|Deequ is a librar...|  389|       awslabs/deequ|143925946|           Scala|        103|               deequ| 2158|         70|[dataquality, spa...|Organization|            awslabs|      Spark|\n",
      "|           null|2017-11-02 16:15:15|TransmogrifAI (pr...|  374|salesforce/Transm...|109289451|           Scala|         44|       TransmogrifAI| 2101|        146|[ml, automl, tran...|Organization|         salesforce|      Spark|\n",
      "|           null|2019-10-22 19:13:09|A new arguably fa...|  179|     rajasekarv/vega|216890889|            Rust|         34|                vega| 2028|        116|                  []|        User|         rajasekarv|      Spark|\n",
      "|           null|2017-05-31 17:30:28|Deep Learning Pip...|  494|databricks/spark-...| 92971378|          Python|         85| spark-deep-learning| 1912|        151|                  []|Organization|         databricks|      Spark|\n",
      "|           null|2018-01-03 17:43:16|Kubernetes operat...|  921|GoogleCloudPlatfo...|116165188|              Go|        327|spark-on-k8s-oper...| 1895|         82|[kubernetes, kube...|Organization|GoogleCloudPlatform|      Spark|\n",
      "|           null|2014-07-25 20:08:44|Oryx 2: Lambda ar...|  412|    OryxProject/oryx| 22269384|            Java|          1|                oryx| 1796|        214|[lambda-architect...|Organization|        OryxProject|      Spark|\n",
      "|           null|2019-04-22 18:55:55|.NET for Apache® ...|  270|        dotnet/spark|182849051|              C#|        140|               spark| 1746|         82|[spark, csharp, d...|Organization|             dotnet|      Spark|\n",
      "|           null|2015-10-08 12:19:32|Apache Spark dock...|  593|big-data-europe/d...| 43886361|           Shell|         38|        docker-spark| 1706|         99|[spark-kubernetes...|Organization|    big-data-europe|      Spark|\n",
      "|           null|2015-08-22 13:52:08|Elassandra = Elas...|  204|strapdata/elassandra| 41209174|            Java|         40|          elassandra| 1624|         87|[cassandra, elast...|Organization|          strapdata|      Spark|\n",
      "|           null|2015-05-06 07:45:21|Apache Spark & Py...|  893|jadianes/spark-py...| 35145949|Jupyter Notebook|          9|  spark-py-notebooks| 1439|         99|[spark, python, p...|        User|           jadianes|      Spark|\n",
      "|           null|2016-06-28 07:00:06|High performance ...|  697|   apache/carbondata| 62117818|           Scala|        138|          carbondata| 1309|        129|[scala, java, big...|Organization|             apache|      Spark|\n",
      "+---------------+-------------------+--------------------+-----+--------------------+---------+----------------+-----------+--------------------+-----+-----------+--------------------+------------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff3b8aca-1128-4fd4-9a52-64794041081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn(\"relevance_score\" , 1.5 * col(\"forks\") + 1.32 * col(\"subscribers\") + 1.04 * col(\"stars\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a78dbe56-c288-48d9-a839-936cc4253e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_grouped = df2.groupBy(\"search_term\").agg(sum(\"relevance_score\").alias(\"relevance_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e046859d-fbac-44f7-a113-194f6235480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "| search_term|   relevance_score|\n",
      "+------------+------------------+\n",
      "|       Spark| 295286.1599999999|\n",
      "|      Hadoop| 584015.9000000012|\n",
      "|      Kotlin|1936763.9000000004|\n",
      "|    React-JS| 870068.3600000012|\n",
      "|  Tensorflow| 3918987.260000002|\n",
      "|      Docker| 4403817.560000001|\n",
      "|         Cpp| 4377811.440000002|\n",
      "|    ethereum| 1157287.259999999|\n",
      "|       Flask| 884822.1200000001|\n",
      "|     Flutter|              null|\n",
      "|       Scala|1287463.6800000004|\n",
      "|     PyTorch| 3357329.079999997|\n",
      "|React-Native|3097924.4600000037|\n",
      "|  Typescript| 4909697.760000003|\n",
      "|  Kubernetes|3540183.0199999996|\n",
      "|      Scikit| 897061.2400000009|\n",
      "|           R|     1.187633824E7|\n",
      "|      NodeJS| 4331014.679999995|\n",
      "|     Threejs|360260.49999999965|\n",
      "|      Django| 1488257.160000001|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "783082ae-da1f-4ac1-875f-291f487f25ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.format(\"jdbc\").option(\"url\", pg2_url).option(\"dbtable\", \"search_terms_relevance\").option(\"user\", \"postgres\").option(\"password\", \"1234\").option(\"driver\", \"org.postgresql.Driver\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d861894-ff08-4c12-84f1-132da67459ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
